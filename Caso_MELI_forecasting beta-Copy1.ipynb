{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50ccf24",
   "metadata": {},
   "source": [
    "# Objetivo de la prueba\n",
    "\n",
    "En este caso, se quiere pronosticar la demanda de un producto para una semana\n",
    "determinada, en una tienda especial. El conjunto de datos que recibe consta de 8 semanas\n",
    "de transacciones de ventas en México.\n",
    "\n",
    "Cada semana, hay camiones de reparto que entregan productos a los vendedores. Cada\n",
    "transacción consiste en ventas y devoluciones. Las devoluciones son los productos que no\n",
    "se han vendido y caducado.\n",
    "\n",
    "La demanda de un producto en una semana determinada se define como las ventas de esta\n",
    "semana restado por el retorno de la próxima semana.\n",
    "\n",
    "## Requisitos\n",
    "\n",
    "● Intentar desarrollar la prueba en Python / R / SQL, o el programa que se le facilite.\n",
    "\n",
    "● Comparte el documento con las respuestas, incluye una breve explicación de tus resultados.\n",
    "\n",
    "● Comparta su código para revisarlo en detalle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a59fd",
   "metadata": {},
   "source": [
    "## Entregables\n",
    "\n",
    "1. Justifica la elección del algoritmo que utilizaste.\n",
    "\n",
    "2. Graficar una serie de tiempo para una determinada combinación producto-cliente-agencia.\n",
    "\n",
    "3. Agregue varias métricas de su elección para mostrar la solidez del algoritmo.\n",
    "\n",
    "4. Definir una muestra de clientes que represente a una agencia específica (Especifique cuál agencia y cuáles fueron sus criterios de selección y metodología aplicada).\n",
    "\n",
    "5. Prediga la semana 9 para los 3 productos más vendidos en la muestra de su cliente.\n",
    "\n",
    "6. Haz un dibujo de diagrama de flujo que mapee todos los pasos de tu algoritmo usado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00483bcc",
   "metadata": {},
   "source": [
    "## Cosas a tener en cuenta\n",
    "\n",
    "● Puede haber productos en el conjunto de prueba que no existen en el conjunto\n",
    "de entrenamiento. Este es el comportamiento de los datos de inventario, ya que\n",
    "hay nuevos productos que se venden todo el tiempo. Tu modelo debería ser\n",
    "capaz de acomodar esto.\n",
    "\n",
    "● Hay Cliente_ID duplicados en cliente_tabla, lo que significa un Cliente_ID. Puede\n",
    "tener múltiples NombreCliente que son muy similares. Esto se debe al\n",
    "NombreCliente ser ruidoso y no estandarizado en los datos sin procesar, por lo\n",
    "que depende de usted decidir cómo limpiar y utilizar esta información.\n",
    "\n",
    "● La demanda ajustada (Demanda_uni_equil) siempre es >= 0 ya que la demanda\n",
    "debería ser un 0 o un valor positivo. La razón que Venta_uni_hoy -\n",
    "Dev_uni_proxima a veces tiene valores negativos es que el los registros de\n",
    "devoluciones a veces se prolongan durante algunas semanas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec0f3f9",
   "metadata": {},
   "source": [
    "## Descripciones de archivos\n",
    "\n",
    "● cliente_tabla.csv: nombres de clientes (se pueden unir con tren/prueba en\n",
    "Cliente_ID)\n",
    "\n",
    "● producto_tabla.csv: nombres de productos (se pueden unir con tren/prueba en\n",
    "Producto_ID)\n",
    "\n",
    "● estados_state.csv: ciudad y estado (se puede unir con tren/prueba en Agencia_ID) Campos de información\n",
    "\n",
    "● Semana — Número de semana (de jueves a miércoles)\n",
    "\n",
    "● Agencia_ID: ID del depósito de ventas\n",
    "\n",
    "● Canal_ID: ID del canal de ventas\n",
    "\n",
    "● Ruta_SAK: ID de ruta (Varias rutas = Depósito de ventas)\n",
    "\n",
    "● Cliente_ID: identificación del cliente\n",
    "\n",
    "● NombreCliente — Nombre del cliente\n",
    "\n",
    "● Producto_ID — Identificación del producto\n",
    "\n",
    "● NombreProducto — Nombre del producto\n",
    "\n",
    "● Venta_uni_hoy: unidad de ventas de esta semana (entero)\n",
    "\n",
    "● Venta_hoy — Ventas esta semana (unidad: pesos)\n",
    "\n",
    "● Dev_uni_proxima: devuelve la unidad la próxima semana (entero)\n",
    "\n",
    "● Dev_proxima — Vuelve la próxima semana (unidad: pesos)\n",
    "\n",
    "● Demanda_uni_equil — Demanda ajustada (entero) (Este es el objetivo que predecir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe051c",
   "metadata": {},
   "source": [
    "# Preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a776b03",
   "metadata": {},
   "source": [
    "## Limpiar tabla de clientes\n",
    "Hay Cliente_ID duplicados en cliente_tabla, lo que significa un Cliente_ID. Puede\n",
    "tener múltiples NombreCliente que son muy similares. \n",
    "\n",
    "Esto se debe al NombreCliente ser ruidoso y no estandarizado en los datos sin procesar, por lo\n",
    "que depende de usted decidir cómo limpiar y utilizar esta información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674344d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar libreria para leer dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7290ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec38017",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incluye el link al CSV de tu Google Drive donde se ha guardado el Data Set\n",
    "ad_df = pd.read_csv('/content/drive/My Drive/advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890acdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f2098",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cargar dataset de cliente mediante url de repositorio publico en github para realizar proceso de data cleaning\n",
    "df_duplicate = pd.read_csv(\"https://media.githubusercontent.com/media/EnriqueEscalante91/Caso-MELI/master/cliente_tabla.csv\")\n",
    "df_duplicate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1978a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Mostrar los primeros registros del DataFrame\n",
    "print(df_duplicate.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f47a049d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros duplicados:\n",
      "        Cliente_ID                            NombreCliente\n",
      "0                0                               SIN NOMBRE\n",
      "1                1                         OXXO XINANTECATL\n",
      "2                2                               SIN NOMBRE\n",
      "3                3                                EL MORENO\n",
      "4                4  SDN SER  DE ALIM  CUERPO SA CIA  DE INT\n",
      "...            ...                                      ...\n",
      "935357    11011586                               OXXO PETEN\n",
      "935358    11693264                     SUPER ABARROTES MARY\n",
      "935359    19988629                          NO IDENTIFICADO\n",
      "935360    99999999                          NO IDENTIFICADO\n",
      "935361  2015152015                          NO IDENTIFICADO\n",
      "\n",
      "[935362 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Validar si existen registros duplicados\n",
    "duplicates = df_duplicate[df_duplicate.duplicated('Cliente_ID')]\n",
    "# Mostrar los registros duplicados\n",
    "print(\"Registros duplicados:\")\n",
    "print(df_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9d4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los registros duplicados en la columna 'Cliente_ID'\n",
    "df_cleaned = df_duplicate.drop_duplicates(subset='Cliente_ID', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6892fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sin duplicados:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el DataFrame resultante\n",
    "print(\"DataFrame sin duplicados:\")\n",
    "print(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85acae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame limpio en un nuevo archivo CSV\n",
    "#csv_filename = \"cliente_tabla_sin_duplicados.csv\"\n",
    "#df.to_csv(csv_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8629477b",
   "metadata": {},
   "source": [
    "# Desarrollo del modelo\n",
    "\n",
    "LSTM (Long Short-Term Memory) en TensorFlow y Keras es altamente recomendado para pronósticos de series temporales debido a su capacidad para capturar patrones a largo plazo y dependencias temporales. Las capas LSTM manejan secuencias variables, conservan información crucial a lo largo del tiempo y evitan problemas de desvanecimiento del gradiente. Ofrecen flexibilidad para configurar hiperparámetros y se integran en modelos Sequential. Estas características los hacen adecuados para capturar relaciones complejas en datos secuenciales y facilitan el pronóstico preciso en problemas de series temporales como la predicción de la demanda basada en datos históricos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13e2b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar libreria pandas en caso de no haber ejecutado antes\n",
    "#import pandas as pd\n",
    "# Importar Tensorflow para nuestro modelo de machine learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "#importar libreria para conectar con base de datos SQL server\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b364a2",
   "metadata": {},
   "source": [
    "## Entregable 1\n",
    "El algoritmo LSTM (Long Short-Term Memory) en un modelo construido con TensorFlow y Keras tiene capacidad para tratar con secuencias de datos, como series temporales, y capturar patrones a largo plazo en los datos. Aquí hay algunas razones para considerar el uso de un modelo LSTM:\n",
    "\n",
    "Captura de Dependencias Temporales: En problemas de pronóstico de series temporales, las dependencias temporales son cruciales. Las capas LSTM están diseñadas para capturar y recordar patrones de dependencia a lo largo del tiempo, lo que las hace ideales para problemas donde la relación entre las observaciones en diferentes momentos es esencial para hacer predicciones precisas.\n",
    "\n",
    "Manejo de Secuencias: Las series temporales y otros tipos de datos secuenciales presentan desafíos únicos en el modelado. Las capas LSTM pueden manejar secuencias de longitud variable y aprender relaciones complejas entre las diferentes entradas en diferentes pasos de tiempo.\n",
    "\n",
    "Memoria a Largo Plazo: A diferencia de las redes neuronales feedforward tradicionales, las LSTM tienen unidades de memoria que les permiten retener información importante a lo largo de la secuencia. Esto permite capturar patrones a largo plazo en los datos, lo que puede ser fundamental para pronósticos precisos en series temporales.\n",
    "\n",
    "Resistencia al Desvanecimiento del Gradiente: Las capas LSTM están diseñadas para mitigar el problema del desvanecimiento del gradiente en redes neuronales profundas. Esto significa que son más efectivas para entrenar en redes profundas con muchas capas, lo que puede ser útil para capturar relaciones complejas en los datos.\n",
    "\n",
    "Flexibilidad: Las capas LSTM pueden configurarse con diferentes hiperparámetros, como la cantidad de unidades LSTM en cada capa, el número de capas LSTM, la función de activación y más. Esto permite ajustar el modelo a las características específicas de tus datos y problema.\n",
    "\n",
    "Pronóstico: Dado que estás interesado en pronosticar la demanda futura basada en datos históricos, un modelo LSTM puede ser particularmente útil, ya que puede capturar patrones y tendencias en las series temporales, permitiéndote hacer predicciones precisas.\n",
    "\n",
    "La combinación de capas LSTM y otras capas, como capas densas (Dense), en un modelo Sequential de Keras te brinda flexibilidad para diseñar y ajustar el modelo según las necesidades de tu conjunto de datos y el problema específico que estás abordando. En resumen, el uso de capas LSTM en un modelo Keras es adecuado para problemas que involucran secuencias temporales y relaciones a largo plazo entre los datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e0faf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15020\\121991145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# cargar dataset de ventas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# este dataset lo utilizaremos como datos de entrenamiento del modelo.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://media.githubusercontent.com/media/EnriqueEscalante91/Caso-MELI/master/dfventas.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[1;31m# open URLs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 667\u001b[1;33m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[0;32m    668\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;31m# Override compression based on Content-Encoding header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"method\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"gzip\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m             \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m         return IOArgs(\n\u001b[0;32m    343\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 476\u001b[1;33m                     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    477\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m             \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1242\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cargar dataset de ventas \n",
    "# este dataset lo utilizaremos como datos de entrenamiento del modelo.\n",
    "df_train = pd.read_csv(\"https://media.githubusercontent.com/media/EnriqueEscalante91/Caso-MELI/master/dfventas.csv\")\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d93195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffb044",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f8ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar dataset test\n",
    "# este dataset lo utilizaremos como datos de prueba para comprobar del modelo.\n",
    "df_test = pd.read_csv(\"https://media.githubusercontent.com/media/EnriqueEscalante91/Caso-MELI/master/dftest.csv\")\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea2b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062477f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf976efb",
   "metadata": {},
   "source": [
    "# Entregable 2\n",
    "Graficar una serie de tiempo para una determinada combinación\n",
    "producto-cliente-agencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c69521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d48162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ca12b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Agrupar y sumar las ventas por producto, agencia y cliente\n",
    "grouped_df = df_train.groupby(['Producto_ID', 'Agencia_ID', 'Cliente_ID'])['Demanda_uni_equil'].sum().reset_index()\n",
    "\n",
    "# Crear el gráfico de dispersión\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(grouped_df['Demanda_uni_equil'], grouped_df['Producto_ID'], alpha=0.5)\n",
    "plt.title('Ventas por Producto, Agencia y Cliente')\n",
    "plt.xlabel('Ventas')\n",
    "plt.ylabel('Producto_ID')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "Este código agrupa los datos por producto, agencia y cliente, suma las ventas y luego crea un gráfico de dispersión con las ventas en el eje x y los códigos de producto en el eje y. Cada punto en el gráfico representa una combinación única de producto, agencia y cliente, y el tamaño de los puntos indica el nivel de ventas. Puedes ajustar el tamaño y la apariencia de los puntos según tus preferencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1eebe1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c29c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e317bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c944e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
